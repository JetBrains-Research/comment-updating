{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CUPytorch.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N5A6hteFMa3"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDbtfOTlEdZE"
      },
      "source": [
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3DzuoEeFtOq"
      },
      "source": [
        "file_id = '1o2qka7h7K1DJhj2hBoK7hLJpxe7gtc2-'\n",
        "destination = 'cup.json'\n",
        "download_file_from_google_drive(file_id, destination)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7dua3kfFu4W"
      },
      "source": [
        "import json\n",
        "with open('cup.json', 'r') as fp:\n",
        "    cup = json.load(fp)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X_VCQL4FwSq",
        "outputId": "9b28672d-7a11-4f59-8c20-93ffd15a9e3b"
      },
      "source": [
        "cup[0].keys()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['C1', 'C2', 'M1', 'M2'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqCM4eq_F2gl"
      },
      "source": [
        "# Filter lenght\n",
        "import numpy as np\n",
        "\n",
        "comment_len_bound = 3\n",
        "code_len_bound = 5\n",
        "\n",
        "mask = np.ones(len(cup), dtype=bool)\n",
        "\n",
        "for i, data in enumerate(cup):\n",
        "  C1 = data['C1']\n",
        "  C2 = data['C2']\n",
        "  M1 = data['M1']\n",
        "  M2 = data['M2']\n",
        "  if len(C1) < comment_len_bound or len(C2) < comment_len_bound or len(M1) < code_len_bound or len(M2) < code_len_bound:\n",
        "    mask[i] = False\n",
        "cup = np.array(cup)[mask]"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRpBeO27GhGj",
        "outputId": "3d108825-fb86-4d29-bbfd-acfbc39ec396"
      },
      "source": [
        "len(cup)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37643"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cta7cg1zG19Q"
      },
      "source": [
        "# Label Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q1nz9MXG4Sj"
      },
      "source": [
        "def create_dataset(data):\n",
        "  dataset = []\n",
        "  for sample in data:\n",
        "    C1 = sample['C1']\n",
        "    C2 = sample['C2']\n",
        "    M1 = sample['M1']\n",
        "    M2 = sample['M2']\n",
        "    # New code and old comment --> inconsistency \n",
        "    dataset.append({'C': C1, 'M': M2, 'Y': 'INCONS'})\n",
        "    # New code and new comment --> consistency\n",
        "    dataset.append({'C': C2, 'M': M2, 'Y': 'CONS'})\n",
        "  return dataset"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiZT6dlQOIb_",
        "outputId": "1ff00ab6-e9b0-43d8-c7b2-71bdae764390"
      },
      "source": [
        "dataset = create_dataset(cup)\n",
        "dataset[0]"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': ['▁get', '▁the', '▁p', 'im', '▁interface'],\n",
              " 'M': ['▁public',\n",
              "  '▁interface',\n",
              "  '▁get',\n",
              "  '▁interface',\n",
              "  '▁return',\n",
              "  '▁this',\n",
              "  '▁onos',\n",
              "  '▁interface'],\n",
              " 'Y': 'INCONS'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnHSBHYOPFr4"
      },
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "Path(\"data\").mkdir(parents=True, exist_ok=True)\n",
        "with open('data/dataset.json', 'w') as f:\n",
        "  for data in dataset:\n",
        "    f.write(json.dumps(data) + '\\n')"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRA3_EylQfoZ",
        "outputId": "6d7637ad-1de9-439d-c7a2-56727f8d3b05"
      },
      "source": [
        "with open('data/dataset.json', 'r') as f:\n",
        "  print(f.read()[:500])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"C\": [\"\\u2581get\", \"\\u2581the\", \"\\u2581p\", \"im\", \"\\u2581interface\"], \"M\": [\"\\u2581public\", \"\\u2581interface\", \"\\u2581get\", \"\\u2581interface\", \"\\u2581return\", \"\\u2581this\", \"\\u2581onos\", \"\\u2581interface\"], \"Y\": \"INCONS\"}\n",
            "{\"C\": [\"\\u2581return\", \"\\u2581the\", \"\\u2581onos\", \"\\u2581interface\"], \"M\": [\"\\u2581public\", \"\\u2581interface\", \"\\u2581get\", \"\\u2581interface\", \"\\u2581return\", \"\\u2581this\", \"\\u2581onos\", \"\\u2581interface\"], \"Y\": \"CONS\"}\n",
            "{\"C\": [\"\\u2581gets\", \"\\u2581ctl\", \"\\u2581schemas\", \"\\u2581\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceB2djW1GlCQ"
      },
      "source": [
        "# NBOW2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzIo8FsXGohQ"
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "CODE = data.Field(tokenize=lambda x: x)\n",
        "COMMENT = data.Field(tokenize=lambda x: x)\n",
        "LABEL = data.LabelField(dtype = torch.float)\n",
        "fields = {'C': ('c', COMMENT), 'M': ('m', CODE), 'Y': ('y', LABEL)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXP_So_3O_Hz"
      },
      "source": [
        "my_data = data.TabularDataset(\n",
        "                            path = 'data/dataset.json',\n",
        "                            format = 'json',\n",
        "                            fields = fields\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzB-ghUQSmEv"
      },
      "source": [
        "print(vars(my_data[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVxmBOqxqcdH"
      },
      "source": [
        "import random\n",
        "SEED = 1234\n",
        "train_data, test_data = my_data.split(random_state = random.seed(SEED))\n",
        "train_data, val_data = train_data.split(split_ratio=0.8, random_state = random.seed(SEED))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CYY7rYsqs8s"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "COMMENT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE)\n",
        "\n",
        "CODE.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkFL5DBPq6gj"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(val_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa74zmNXrGbA"
      },
      "source": [
        "print(f\"Unique tokens in COMMENT vocabulary: {len(COMMENT.vocab)}\")\n",
        "print(f\"Unique tokens in CODE vocabulary: {len(CODE.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGidh3DirTMy"
      },
      "source": [
        "print(CODE.vocab.freqs.most_common(20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAwSdvsbrXPz"
      },
      "source": [
        "print(COMMENT.vocab.freqs.most_common(20))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otV75gtXrZnw"
      },
      "source": [
        "print(COMMENT.vocab.itos[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAvTRxZMrfAe"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJonXfC1tk1s"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, val_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key=lambda x: len(x.c) + len(x.m), # the BucketIterator needs to be told what function it should use to group the data.\n",
        "    sort_within_batch=False,\n",
        "    device = device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCK1oVnwvIFE"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NBOW2(nn.Module):\n",
        "    def __init__(self, comment_vocab_size, code_vocab_size, embedding_dim, output_dim, comment_pad_idx, code_pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding1 = nn.Embedding(comment_vocab_size, embedding_dim, padding_idx=comment_pad_idx)\n",
        "        self.embedding2 = nn.Embedding(code_vocab_size, embedding_dim, padding_idx=code_pad_idx)\n",
        "        \n",
        "        self.fc = nn.Linear(2 * embedding_dim, output_dim)\n",
        "        \n",
        "        self.a1 = torch.nn.Parameter(torch.zeros(embedding_dim, 1))\n",
        "        self.a2 = torch.nn.Parameter(torch.zeros(embedding_dim, 1))\n",
        "        \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "        \n",
        "    def forward(self, comment, code):\n",
        "        \n",
        "        #comment = [comment len, batch size]\n",
        "        #code = [code len, batch size]\n",
        "        \n",
        "        embedded1 = self.embedding1(comment)\n",
        "        embedded2 = self.embedding2(code)\n",
        "\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        embedded1 = embedded1.permute(1, 0, 2)\n",
        "        embedded2 = embedded2.permute(1, 0, 2)\n",
        "  \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        # Get the scalar word importance weights for each word w\n",
        "        # a: [emb dim, 1]\n",
        "        # aw: [batch size, sent len, 1]\n",
        "        \n",
        "        aw1 = torch.matmul(embedded1, self.a1)\n",
        "        aw1 = self.sigmoid(aw1)\n",
        "\n",
        "        aw2 = torch.matmul(embedded2, self.a2)\n",
        "        aw2 = self.sigmoid(aw2)\n",
        "        \n",
        "        # w_emb: [batch size, sent len, emb dim]\n",
        "        weighted_embed1 = embedded1 * aw1\n",
        "        weighted_embed2 = embedded2 * aw2\n",
        "\n",
        "        pooled1 = F.avg_pool2d(weighted_embed1, (weighted_embed1.shape[1], 1)).squeeze(1) \n",
        "        pooled2 = F.avg_pool2d(weighted_embed2, (weighted_embed2.shape[1], 1)).squeeze(1)\n",
        "        #pooled = [batch size, embedding_dim]\n",
        "\n",
        "        code_comment = torch.cat((pooled1, pooled2), dim=1)\n",
        "                \n",
        "        return self.fc(code_comment)\n",
        "      \n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "\n",
        "        self.a1.data.uniform_(0.0, 1.0)\n",
        "        self.a2.data.uniform_(0.0, 1.0)\n",
        "\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ctv05YYUvIzg"
      },
      "source": [
        "CODE_INPUT_DIM = len(CODE.vocab)\n",
        "COMMENT_INPUT_DIM = len(COMMENT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "OUTPUT_DIM = 1\n",
        "COMMENT_PAD_IDX = COMMENT.vocab.stoi[COMMENT.pad_token]\n",
        "CODE_PAD_IDX = CODE.vocab.stoi[CODE.pad_token]\n",
        "model = NBOW2(COMMENT_INPUT_DIM, CODE_INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, COMMENT_PAD_IDX, CODE_PAD_IDX)\n",
        "model.init_weights()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3DImvooxhTx"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNpIAZG4xjax"
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J-fgUYQxspf"
      },
      "source": [
        "COMMENT_UNK_IDX = COMMENT.vocab.stoi[COMMENT.unk_token]\n",
        "CODE_UNK_IDX = CODE.vocab.stoi[CODE.unk_token]\n",
        "\n",
        "model.embedding1.weight.data[COMMENT_UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding1.weight.data[COMMENT_PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "\n",
        "model.embedding2.weight.data[CODE_UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding2.weight.data[CODE_PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjIfSRGUx9NL"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CecIOIwx-m8"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljjH-Cvpx_2J"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLOwDs0ByBAc"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.c, batch.m).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.y)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbL07iklyCgk"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.c, batch.m).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.y)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.y)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeaVkivryNMI"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQkB-UrUyOTM"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAR3mCE4kji5"
      },
      "source": [
        "# NBOW2 + Pretrained Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y2CuHFNkji6"
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "CODE = data.Field(tokenize=lambda x: x, preprocessing=lambda x: [w.replace('▁', '') for w in x])\n",
        "COMMENT = data.Field(tokenize=lambda x: x, preprocessing=lambda x: [w.replace('▁', '') for w in x])\n",
        "LABEL = data.LabelField(dtype = torch.float)\n",
        "fields = {'C': ('c', COMMENT), 'M': ('m', CODE), 'Y': ('y', LABEL)}"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xz7GLktkji7"
      },
      "source": [
        "my_data = data.TabularDataset(\n",
        "                            path = 'data/dataset.json',\n",
        "                            format = 'json',\n",
        "                            fields = fields\n",
        ")"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnSqGCUVkji7",
        "outputId": "6aa32c6e-77fa-4b55-e5b7-7cc5760ecc87"
      },
      "source": [
        "print(vars(my_data[0]))"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'c': ['get', 'the', 'p', 'im', 'interface'], 'm': ['public', 'interface', 'get', 'interface', 'return', 'this', 'onos', 'interface'], 'y': 'INCONS'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KCK34Q2kji9"
      },
      "source": [
        "import random\n",
        "SEED = 1234\n",
        "train_data, test_data = my_data.split(random_state = random.seed(SEED))\n",
        "train_data, val_data = train_data.split(split_ratio=0.8, random_state = random.seed(SEED))"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIOn3_cnkji9"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "COMMENT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE,  \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "CODE.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE,  \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS_Y7YIEyhQG",
        "outputId": "3a7c662c-508d-4815-93cb-47f0e5d0b0cb"
      },
      "source": [
        "import torchtext.vocab\n",
        "\n",
        "glove = torchtext.vocab.GloVe(name = '6B', dim = 100)\n",
        "\n",
        "print(f'There are {len(glove.itos)} words in the vocabulary')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 400000 words in the vocabulary\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Qadd0Xdyj11",
        "outputId": "58df557b-8d6d-4c14-c37c-e2c21a0becb6"
      },
      "source": [
        "count_intersect = 0\n",
        "for w in COMMENT.vocab.itos:\n",
        "  if w in glove.stoi:\n",
        "    count_intersect += 1\n",
        "\n",
        "print(count_intersect / len(COMMENT.vocab.itos))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8441480292849263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDDc_AJ6z40O",
        "outputId": "758847e9-47c3-4034-829f-e1d8d4b916cd"
      },
      "source": [
        "count_intersect = 0\n",
        "for w in CODE.vocab.itos:\n",
        "  if w in glove.stoi:\n",
        "    count_intersect += 1\n",
        "\n",
        "print(count_intersect / len(CODE.vocab.itos))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.751122357358583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw0ldATSkji9",
        "outputId": "6dc8865b-20af-4d65-e296-0deb08ea239b"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(val_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 42160\n",
            "Number of validation examples: 10540\n",
            "Number of testing examples: 22586\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__sXspo9kji9",
        "outputId": "1466d740-e2b6-4f4d-a7d7-a7258c2a0dae"
      },
      "source": [
        "print(f\"Unique tokens in COMMENT vocabulary: {len(COMMENT.vocab)}\")\n",
        "print(f\"Unique tokens in CODE vocabulary: {len(CODE.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in COMMENT vocabulary: 9971\n",
            "Unique tokens in CODE vocabulary: 12251\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBs0hpx5kji-",
        "outputId": "a38d3fd3-5f36-4085-a203-6a11edb70605"
      },
      "source": [
        "print(CODE.vocab.freqs.most_common(20))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('get', 65544), ('return', 42390), ('if', 38228), ('string', 37965), ('new', 35885), ('public', 35560), ('name', 26251), ('exception', 22761), ('set', 21113), ('request', 19418), ('list', 18079), ('int', 17882), ('final', 17441), ('type', 17128), ('this', 16661), ('value', 15983), ('void', 15689), ('id', 15409), ('to', 15092), ('class', 14103)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCzAZ_HWkji-",
        "outputId": "7e1c76be-2012-4227-fb25-54e82a64aec3"
      },
      "source": [
        "print(COMMENT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 43775), ('a', 17053), ('of', 12110), ('to', 11661), ('and', 7677), ('link', 7646), ('is', 7342), ('for', 7225), ('this', 6237), ('in', 6079), ('returns', 5384), ('if', 5090), ('given', 4635), ('that', 4181), ('an', 4150), ('with', 4002), ('from', 3479), ('code', 3436), ('be', 3418), ('value', 3320)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii3sNOyAkji-",
        "outputId": "f214627c-e61f-41b4-fb07-d42525e84eb9"
      },
      "source": [
        "print(COMMENT.vocab.itos[:10])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', 'a', 'of', 'to', 'and', 'link', 'is', 'for']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPmXUxO3kji-",
        "outputId": "01c2f937-1356-4609-d1a8-29a9b51a0ba7"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f1b5040f730>, {'INCONS': 0, 'CONS': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju2SLHnJkji-"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, val_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key=lambda x: len(x.c) + len(x.m), # the BucketIterator needs to be told what function it should use to group the data.\n",
        "    sort_within_batch=False,\n",
        "    device = device)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHszgTc6kji-"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NBOW2(nn.Module):\n",
        "    def __init__(self, comment_vocab_size, code_vocab_size, embedding_dim, output_dim, \n",
        "                 comment_pad_idx, code_pad_idx, dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding1 = nn.Embedding(comment_vocab_size, embedding_dim, padding_idx=comment_pad_idx)\n",
        "        self.embedding2 = nn.Embedding(code_vocab_size, embedding_dim, padding_idx=code_pad_idx)\n",
        "        \n",
        "        self.fc = nn.Linear(2 * embedding_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.a1 = torch.nn.Parameter(torch.zeros(embedding_dim, 1))\n",
        "        self.a2 = torch.nn.Parameter(torch.zeros(embedding_dim, 1))\n",
        "        \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "        \n",
        "    def forward(self, comment, code):\n",
        "        \n",
        "        #comment = [comment len, batch size]\n",
        "        #code = [code len, batch size]\n",
        "        \n",
        "        embedded1 = self.embedding1(comment)\n",
        "        embedded2 = self.embedding2(code)\n",
        "\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        embedded1 = embedded1.permute(1, 0, 2)\n",
        "        embedded2 = embedded2.permute(1, 0, 2)\n",
        "  \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        # Get the scalar word importance weights for each word w\n",
        "        # a: [emb dim, 1]\n",
        "        # aw: [batch size, sent len, 1]\n",
        "        \n",
        "        aw1 = torch.matmul(embedded1, self.a1)\n",
        "        aw1 = self.sigmoid(aw1)\n",
        "\n",
        "        aw2 = torch.matmul(embedded2, self.a2)\n",
        "        aw2 = self.sigmoid(aw2)\n",
        "        \n",
        "        # w_emb: [batch size, sent len, emb dim]\n",
        "        weighted_embed1 = embedded1 * aw1\n",
        "        weighted_embed2 = embedded2 * aw2\n",
        "\n",
        "        pooled1 = F.avg_pool2d(weighted_embed1, (weighted_embed1.shape[1], 1)).squeeze(1) \n",
        "        pooled2 = F.avg_pool2d(weighted_embed2, (weighted_embed2.shape[1], 1)).squeeze(1)\n",
        "        #pooled = [batch size, embedding_dim]\n",
        "\n",
        "        code_comment = self.dropout(torch.cat((pooled1, pooled2), dim=1))\n",
        "                \n",
        "        return self.fc(code_comment)\n",
        "      \n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "\n",
        "        self.a1.data.uniform_(0.0, 1.0)\n",
        "        self.a2.data.uniform_(0.0, 1.0)\n",
        "\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQH1ETBXkji-"
      },
      "source": [
        "CODE_INPUT_DIM = len(CODE.vocab)\n",
        "COMMENT_INPUT_DIM = len(COMMENT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "OUTPUT_DIM = 1\n",
        "COMMENT_PAD_IDX = COMMENT.vocab.stoi[COMMENT.pad_token]\n",
        "CODE_PAD_IDX = CODE.vocab.stoi[CODE.pad_token]\n",
        "DROPOUT = 0.5\n",
        "\n",
        "model = NBOW2(COMMENT_INPUT_DIM, CODE_INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, COMMENT_PAD_IDX, CODE_PAD_IDX, DROPOUT)\n",
        "model.init_weights()"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmysTxOtqbo8"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JIkh4JGkji_",
        "outputId": "c32c0fb5-d9ed-4a9e-ceee-eb82de6bb413"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 2,222,601 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmmb4_qikji_",
        "outputId": "9acffbdb-846f-4e53-bf68-a8cbcd813109"
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a1\n",
            "a2\n",
            "embedding1.weight\n",
            "embedding2.weight\n",
            "fc.weight\n",
            "fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAPh1bonqekn",
        "outputId": "51a532de-404d-40e0-bc66-382a32e49828"
      },
      "source": [
        "pretrained_embeddings = COMMENT.vocab.vectors\n",
        "\n",
        "model.embedding1.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "pretrained_embeddings = CODE.vocab.vectors\n",
        "\n",
        "model.embedding2.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.9197,  1.2477,  0.8128,  ..., -0.3548,  1.9117, -0.3136],\n",
              "        [-0.4103, -0.6661,  0.4244,  ...,  0.4425,  1.7003,  0.0539],\n",
              "        [ 0.1443,  0.4395,  0.5832,  ...,  0.5013,  0.4954,  0.4992],\n",
              "        ...,\n",
              "        [ 0.7680,  0.7413, -0.2156,  ...,  0.8223,  0.0310, -1.6101],\n",
              "        [-0.4131,  0.5306,  0.1404,  ..., -0.1758, -0.3542,  0.2784],\n",
              "        [ 0.5877, -0.0255, -0.5765,  ..., -0.4431, -0.2355, -0.3533]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjsNrBChkji_"
      },
      "source": [
        "COMMENT_UNK_IDX = COMMENT.vocab.stoi[COMMENT.unk_token]\n",
        "CODE_UNK_IDX = CODE.vocab.stoi[CODE.unk_token]\n",
        "\n",
        "model.embedding1.weight.data[COMMENT_UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding1.weight.data[COMMENT_PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "\n",
        "model.embedding2.weight.data[CODE_UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding2.weight.data[CODE_PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drjQlJL_qd3l"
      },
      "source": [
        ""
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZUSW8Rqkji_"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66zLWzydkji_"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4CGCCV0kji_"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PG3x059kji_"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.c, batch.m).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.y)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZdt_5sakji_"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.c, batch.m).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.y)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.y)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DMGY6pZkji_"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKLd7VBBkji_",
        "outputId": "ccadeb6d-db10-4960-c1a1-bdc23e57e1ce"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.696 | Train Acc: 50.05%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 49.64%\n",
            "Epoch: 02 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.689 | Train Acc: 52.78%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 48.76%\n",
            "Epoch: 03 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.684 | Train Acc: 55.21%\n",
            "\t Val. Loss: 0.696 |  Val. Acc: 48.78%\n",
            "Epoch: 04 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.677 | Train Acc: 56.67%\n",
            "\t Val. Loss: 0.700 |  Val. Acc: 48.67%\n",
            "Epoch: 05 | Epoch Time: 0m 4s\n",
            "\tTrain Loss: 0.670 | Train Acc: 58.45%\n",
            "\t Val. Loss: 0.706 |  Val. Acc: 48.66%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "av6t1uro3G2b",
        "outputId": "c6b029b6-b92f-4feb-f6dc-10164281be52"
      },
      "source": [
        "model.load_state_dict(torch.load('tut3-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.696 | Test Acc: 49.39%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRqfoqHV5AJY"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA52OZY45AJY"
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "CODE = data.Field(tokenize=lambda x: x, preprocessing=lambda x: [w.replace('▁', '') for w in x], include_lengths = True)\n",
        "COMMENT = data.Field(tokenize=lambda x: x, preprocessing=lambda x: [w.replace('▁', '') for w in x], include_lengths = True)\n",
        "LABEL = data.LabelField(dtype = torch.float)\n",
        "fields = {'C': ('c', COMMENT), 'M': ('m', CODE), 'Y': ('y', LABEL)}"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUFpbl6C5AJZ"
      },
      "source": [
        "my_data = data.TabularDataset(\n",
        "                            path = 'data/dataset.json',\n",
        "                            format = 'json',\n",
        "                            fields = fields\n",
        ")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfVf4KR_5AJZ",
        "outputId": "897d9cd7-67ac-4f4f-eb86-e439969ef7b9"
      },
      "source": [
        "print(vars(my_data[0]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'c': ['get', 'the', 'p', 'im', 'interface'], 'm': ['public', 'interface', 'get', 'interface', 'return', 'this', 'onos', 'interface'], 'y': 'INCONS'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdDOmTPF5AJb"
      },
      "source": [
        "import random\n",
        "SEED = 1234\n",
        "train_data, test_data = my_data.split(random_state = random.seed(SEED))\n",
        "train_data, val_data = train_data.split(split_ratio=0.8, random_state = random.seed(SEED))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrX0nSsv5AJb"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "COMMENT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE,  \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "CODE.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE,  \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoLv3euS5AJb",
        "outputId": "f6f0f691-8e95-4042-be0a-0341cccd6703"
      },
      "source": [
        "import torchtext.vocab\n",
        "\n",
        "glove = torchtext.vocab.GloVe(name = '6B', dim = 100)\n",
        "\n",
        "print(f'There are {len(glove.itos)} words in the vocabulary')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 400000 words in the vocabulary\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHZUpnYK5AJc",
        "outputId": "67b094fd-f5f0-4433-a723-2e7624ad1ae8"
      },
      "source": [
        "count_intersect = 0\n",
        "for w in COMMENT.vocab.itos:\n",
        "  if w in glove.stoi:\n",
        "    count_intersect += 1\n",
        "\n",
        "print(count_intersect / len(COMMENT.vocab.itos))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8441480292849263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3K_AQ7U5AJc",
        "outputId": "e0920446-60ab-4544-df70-488c100921b3"
      },
      "source": [
        "count_intersect = 0\n",
        "for w in CODE.vocab.itos:\n",
        "  if w in glove.stoi:\n",
        "    count_intersect += 1\n",
        "\n",
        "print(count_intersect / len(CODE.vocab.itos))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.751122357358583\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJtW2j015AJc",
        "outputId": "37e094f7-d04a-4edb-dad8-080f19477e24"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(val_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 42160\n",
            "Number of validation examples: 10540\n",
            "Number of testing examples: 22586\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9xeyvhx5AJd",
        "outputId": "2afa1da5-cb0e-4cce-be90-d0dadd1f35a1"
      },
      "source": [
        "print(f\"Unique tokens in COMMENT vocabulary: {len(COMMENT.vocab)}\")\n",
        "print(f\"Unique tokens in CODE vocabulary: {len(CODE.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in COMMENT vocabulary: 9971\n",
            "Unique tokens in CODE vocabulary: 12251\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfIIf2Go5AJd",
        "outputId": "59bf75de-b9d7-4888-8843-b1d206d56418"
      },
      "source": [
        "print(CODE.vocab.freqs.most_common(20))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('get', 65544), ('return', 42390), ('if', 38228), ('string', 37965), ('new', 35885), ('public', 35560), ('name', 26251), ('exception', 22761), ('set', 21113), ('request', 19418), ('list', 18079), ('int', 17882), ('final', 17441), ('type', 17128), ('this', 16661), ('value', 15983), ('void', 15689), ('id', 15409), ('to', 15092), ('class', 14103)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hedObpWx5AJd",
        "outputId": "cc1766bf-706e-425e-8638-87b81771273c"
      },
      "source": [
        "print(COMMENT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 43775), ('a', 17053), ('of', 12110), ('to', 11661), ('and', 7677), ('link', 7646), ('is', 7342), ('for', 7225), ('this', 6237), ('in', 6079), ('returns', 5384), ('if', 5090), ('given', 4635), ('that', 4181), ('an', 4150), ('with', 4002), ('from', 3479), ('code', 3436), ('be', 3418), ('value', 3320)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-b3EgKo5AJd",
        "outputId": "adafbce2-90a1-48e1-d341-051a089a07dd"
      },
      "source": [
        "print(COMMENT.vocab.itos[:10])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', 'a', 'of', 'to', 'and', 'link', 'is', 'for']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRSZTBFL5AJe",
        "outputId": "db42151e-7dbf-44a7-d241-860bdc723cc0"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7fbfba628510>, {'INCONS': 0, 'CONS': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX12gMt65AJe"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, val_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort=False,\n",
        "    device = device)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uncc3q3z5AJe"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, comment_vocab_size, code_vocab_size, \n",
        "                 embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, comment_pad_idx, code_pad_idx, dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding1 = nn.Embedding(comment_vocab_size, embedding_dim, padding_idx = comment_pad_idx)\n",
        "        self.embedding2 = nn.Embedding(code_vocab_size, embedding_dim, padding_idx = code_pad_idx)\n",
        "        \n",
        "        self.rnn1 = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout)\n",
        "        \n",
        "        self.rnn2 = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout)\n",
        "        \n",
        "\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * 2 * 2, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, comment, comment_lengths, code, code_lengths):\n",
        "        \n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded1 = self.dropout(self.embedding1(comment))\n",
        "        embedded2 = self.dropout(self.embedding2(code))\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        #pack sequence\n",
        "        packed_embedded1 = nn.utils.rnn.pack_padded_sequence(embedded1, comment_lengths.cpu(), enforce_sorted=False)\n",
        "        packed_output1, (hidden1, cell1) = self.rnn1(packed_embedded1)\n",
        "\n",
        "        packed_embedded2 = nn.utils.rnn.pack_padded_sequence(embedded2, code_lengths.cpu(), enforce_sorted=False)\n",
        "        packed_output2, (hidden2, cell2) = self.rnn2(packed_embedded2)\n",
        "\n",
        "        \n",
        "        #unpack sequence\n",
        "        output1, output_lengths1 = nn.utils.rnn.pad_packed_sequence(packed_output1)\n",
        "        output2, output_lengths2 = nn.utils.rnn.pad_packed_sequence(packed_output1)\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * num directions]\n",
        "        #output over padding tokens are zero tensors\n",
        "        \n",
        "        #hidden = [num layers * num directions, batch size, hid dim]\n",
        "        #cell = [num layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        #and apply dropout\n",
        "        \n",
        "        hidden1 = self.dropout(torch.cat((hidden1[-2,:,:], hidden1[-1,:,:]), dim = 1))\n",
        "        hidden2 = self.dropout(torch.cat((hidden2[-2,:,:], hidden2[-1,:,:]), dim = 1))\n",
        "\n",
        "        hidden = self.dropout(torch.cat((hidden1, hidden2), dim=1))\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "            \n",
        "        return self.fc(hidden)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgrgpb025AJe"
      },
      "source": [
        "CODE_INPUT_DIM = len(CODE.vocab)\n",
        "COMMENT_INPUT_DIM = len(COMMENT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "OUTPUT_DIM = 1\n",
        "COMMENT_PAD_IDX = COMMENT.vocab.stoi[COMMENT.pad_token]\n",
        "CODE_PAD_IDX = CODE.vocab.stoi[CODE.pad_token]\n",
        "DROPOUT = 0.5\n",
        "BIDIRECTIONAL = True\n",
        "N_LAYERS = 2\n",
        "HIDDEN_DIM = 256\n",
        "\n",
        "model = RNN(COMMENT_INPUT_DIM, CODE_INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, COMMENT_PAD_IDX, CODE_PAD_IDX, \n",
        "            DROPOUT)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mz8Btup5AJe"
      },
      "source": [
        ""
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Euv4-dKK5AJe",
        "outputId": "a091a38d-96de-4b59-dd7c-18117e94aac4"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 6,843,513 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwvOB0Pa5AJe",
        "outputId": "b057c86f-917b-4f47-b7b0-b2ee4db0c816"
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embedding1.weight\n",
            "embedding2.weight\n",
            "rnn1.weight_ih_l0\n",
            "rnn1.weight_hh_l0\n",
            "rnn1.bias_ih_l0\n",
            "rnn1.bias_hh_l0\n",
            "rnn1.weight_ih_l0_reverse\n",
            "rnn1.weight_hh_l0_reverse\n",
            "rnn1.bias_ih_l0_reverse\n",
            "rnn1.bias_hh_l0_reverse\n",
            "rnn1.weight_ih_l1\n",
            "rnn1.weight_hh_l1\n",
            "rnn1.bias_ih_l1\n",
            "rnn1.bias_hh_l1\n",
            "rnn1.weight_ih_l1_reverse\n",
            "rnn1.weight_hh_l1_reverse\n",
            "rnn1.bias_ih_l1_reverse\n",
            "rnn1.bias_hh_l1_reverse\n",
            "rnn2.weight_ih_l0\n",
            "rnn2.weight_hh_l0\n",
            "rnn2.bias_ih_l0\n",
            "rnn2.bias_hh_l0\n",
            "rnn2.weight_ih_l0_reverse\n",
            "rnn2.weight_hh_l0_reverse\n",
            "rnn2.bias_ih_l0_reverse\n",
            "rnn2.bias_hh_l0_reverse\n",
            "rnn2.weight_ih_l1\n",
            "rnn2.weight_hh_l1\n",
            "rnn2.bias_ih_l1\n",
            "rnn2.bias_hh_l1\n",
            "rnn2.weight_ih_l1_reverse\n",
            "rnn2.weight_hh_l1_reverse\n",
            "rnn2.bias_ih_l1_reverse\n",
            "rnn2.bias_hh_l1_reverse\n",
            "fc.weight\n",
            "fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEtlDJXA5AJe",
        "outputId": "00894c48-4a25-41bc-e5fb-47a834861f6e"
      },
      "source": [
        "pretrained_embeddings = COMMENT.vocab.vectors\n",
        "\n",
        "model.embedding1.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "pretrained_embeddings = CODE.vocab.vectors\n",
        "\n",
        "model.embedding2.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.3390, -0.5360,  0.1918,  ..., -0.4738, -0.7479, -1.6854],\n",
              "        [-0.1583,  0.1371, -0.7183,  ..., -0.7116, -0.7041, -0.4214],\n",
              "        [ 0.1443,  0.4395,  0.5832,  ...,  0.5013,  0.4954,  0.4992],\n",
              "        ...,\n",
              "        [ 0.1713, -1.1731,  2.0175,  ...,  0.1772, -1.1146, -0.0331],\n",
              "        [-0.4131,  0.5306,  0.1404,  ..., -0.1758, -0.3542,  0.2784],\n",
              "        [ 0.5877, -0.0255, -0.5765,  ..., -0.4431, -0.2355, -0.3533]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsJOc_E55AJf"
      },
      "source": [
        "COMMENT_UNK_IDX = COMMENT.vocab.stoi[COMMENT.unk_token]\n",
        "CODE_UNK_IDX = CODE.vocab.stoi[CODE.unk_token]\n",
        "\n",
        "model.embedding1.weight.data[COMMENT_UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding1.weight.data[COMMENT_PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "\n",
        "model.embedding2.weight.data[CODE_UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding2.weight.data[CODE_PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYmpHMIz5AJf"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJINOqZL5AJf"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3rpMoGz5AJf"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVdJiKwf5AJf"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        comment, comment_lens = batch.c\n",
        "        code, code_lens = batch.m\n",
        "        predictions = model(comment, comment_lens, code, code_lens).squeeze(1)\n",
        "            \n",
        "        loss = criterion(predictions, batch.y)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjuiQ_iY5AJf"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            comment, comment_lens = batch.c\n",
        "            code, code_lens = batch.m\n",
        "            predictions = model(comment, comment_lens, code, code_lens).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.y)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.y)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TXHnlRw5AJf"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzvfwDid5AJf",
        "outputId": "4755560e-58ae-4299-bbde-f312ee36c295"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 53s\n",
            "\tTrain Loss: 0.693 | Train Acc: 50.52%\n",
            "\t Val. Loss: 0.683 |  Val. Acc: 52.92%\n",
            "Epoch: 02 | Epoch Time: 0m 53s\n",
            "\tTrain Loss: 0.682 | Train Acc: 52.80%\n",
            "\t Val. Loss: 0.680 |  Val. Acc: 52.12%\n",
            "Epoch: 03 | Epoch Time: 0m 53s\n",
            "\tTrain Loss: 0.673 | Train Acc: 55.10%\n",
            "\t Val. Loss: 0.676 |  Val. Acc: 52.85%\n",
            "Epoch: 04 | Epoch Time: 0m 53s\n",
            "\tTrain Loss: 0.664 | Train Acc: 57.71%\n",
            "\t Val. Loss: 0.674 |  Val. Acc: 53.36%\n",
            "Epoch: 05 | Epoch Time: 0m 53s\n",
            "\tTrain Loss: 0.649 | Train Acc: 59.87%\n",
            "\t Val. Loss: 0.679 |  Val. Acc: 53.35%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWTJXYYF5AJg",
        "outputId": "e2439676-c2d2-47fb-ad29-ac8f85cf9555"
      },
      "source": [
        "model.load_state_dict(torch.load('tut3-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.674 | Test Acc: 52.98%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXPfhMamEWqh"
      },
      "source": [
        "# Transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZP_YNB0EZRU"
      },
      "source": [
        "import torch\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJIh1z1zFFla",
        "outputId": "457594ba-83c1-4af7-c974-693687e4d14c"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A2ctDVOEfDK"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6hcnI5cGOVt",
        "outputId": "ee863b1c-0530-4711-84e5-723057acac96"
      },
      "source": [
        "tokens = tokenizer.tokenize('Hello WORLD how ARE yoU?')\n",
        "\n",
        "print(tokens)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['hello', 'world', 'how', 'are', 'you', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kd88SYQGQkG",
        "outputId": "ad3cbded-8bd0-4ddd-c961-08fa487d9cf5"
      },
      "source": [
        "indexes = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(indexes)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7592, 2088, 2129, 2024, 2017, 1029]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScqbI9v4GS-C",
        "outputId": "a575edba-edb3-45ba-a230-e77e08cb725d"
      },
      "source": [
        "init_token = tokenizer.cls_token\n",
        "eos_token = tokenizer.sep_token\n",
        "pad_token = tokenizer.pad_token\n",
        "unk_token = tokenizer.unk_token\n",
        "\n",
        "print(init_token, eos_token, pad_token, unk_token)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] [SEP] [PAD] [UNK]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGIlGFV2GUvg",
        "outputId": "975a8b3e-59cd-40db-c19a-e42be15ac1a0"
      },
      "source": [
        "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
        "eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n",
        "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
        "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
        "\n",
        "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "101 102 0 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAfK_-NYGW7d",
        "outputId": "b80a8478-6ee6-4d4c-a438-c7dd8a983f2b"
      },
      "source": [
        "max_input_length = tokenizer.max_model_input_sizes['bert-base-uncased']\n",
        "\n",
        "print(max_input_length)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4v4vQL6GabS"
      },
      "source": [
        "def tokenize_and_cut(sentence):\n",
        "    sentence = [w.replace('▁', '') for w in sentence]\n",
        "    sentence = ' '.join(sentence)\n",
        "    tokens = tokenizer.tokenize(sentence) \n",
        "    tokens = tokens[:max_input_length-2]\n",
        "    return tokenizer.convert_tokens_to_ids(tokens)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lcNV6JaHUo2",
        "outputId": "b5b8de35-3a91-4884-90be-f331190c5f3a"
      },
      "source": [
        "tokenize_and_cut(cup[0]['M2'])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2270, 8278, 2131, 8278, 2709, 2023, 21058, 2015, 8278]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnoA6YkVGewt"
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "CODE = data.Field(batch_first = True,\n",
        "                  use_vocab = False,\n",
        "                  tokenize = lambda x: x,\n",
        "                  preprocessing = tokenize_and_cut,\n",
        "                  init_token = init_token_idx,\n",
        "                  eos_token = eos_token_idx,\n",
        "                  pad_token = pad_token_idx,\n",
        "                  unk_token = unk_token_idx)\n",
        "\n",
        "COMMENT = data.Field(batch_first = True,\n",
        "                  use_vocab = False,\n",
        "                  tokenize = lambda x: x,\n",
        "                  preprocessing = tokenize_and_cut,\n",
        "                  init_token = init_token_idx,\n",
        "                  eos_token = eos_token_idx,\n",
        "                  pad_token = pad_token_idx,\n",
        "                  unk_token = unk_token_idx)\n",
        "LABEL = data.LabelField(dtype = torch.float)\n",
        "fields = {'C': ('c', COMMENT), 'M': ('m', CODE), 'Y': ('y', LABEL)}"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W35MDCWG_0E"
      },
      "source": [
        "my_data = data.TabularDataset(\n",
        "                            path = 'data/dataset.json',\n",
        "                            format = 'json',\n",
        "                            fields = fields\n",
        ")"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IJBQkNTHGnR",
        "outputId": "e663eb4c-9f9a-4ec0-fd02-4c0cb3c23476"
      },
      "source": [
        "print(vars(my_data[0])) "
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'c': [2131, 1996, 1052, 10047, 8278], 'm': [2270, 8278, 2131, 8278, 2709, 2023, 21058, 2015, 8278], 'y': 'INCONS'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCEFE3-UM_NS",
        "outputId": "78aa7964-01f4-42e9-a86a-fe6c5b3f0198"
      },
      "source": [
        "print(tokenizer.convert_ids_to_tokens(vars(my_data[2])['c']))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['gets', 'ct', '##l', 'sc', '##hema', '##s', 'with', 'the', 'given', 'fully', 'qualified', 'name']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I4g5ncAFNI3t"
      },
      "source": [
        "import random\n",
        "SEED = 1234\n",
        "train_data, test_data = my_data.split(random_state = random.seed(SEED))\n",
        "train_data, val_data = train_data.split(split_ratio=0.8, random_state = random.seed(SEED))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HEvoW1gNPJT",
        "outputId": "b35abf5b-de2f-432f-cb6e-e8a968a9108a"
      },
      "source": [
        "print(f\"Number of training examples: {len(train_data)}\")\n",
        "print(f\"Number of validation examples: {len(val_data)}\")\n",
        "print(f\"Number of testing examples: {len(test_data)}\")"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 42160\n",
            "Number of validation examples: 10540\n",
            "Number of testing examples: 22586\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV13Lcm2NRlD"
      },
      "source": [
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOtV9uckNbw2",
        "outputId": "404b95fc-1632-4c24-cece-9a8c81a7bfe7"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7fbfba628510>, {'INCONS': 0, 'CONS': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeyIUzywNcsn"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, val_data, test_data), \n",
        "    batch_size = BATCH_SIZE, \n",
        "    device = device, \n",
        "    sort=False)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35rAIDDlNfXe"
      },
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "bert = BertModel.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SzAlW2eNidi"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class BERTGRU(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 bidirectional,\n",
        "                 dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.bert = bert\n",
        "        \n",
        "        embedding_dim = bert.config.to_dict()['hidden_size']\n",
        "        \n",
        "        self.rnn1 = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers = n_layers,\n",
        "                          bidirectional = bidirectional,\n",
        "                          batch_first = True,\n",
        "                          dropout = 0 if n_layers < 2 else dropout)\n",
        "        \n",
        "        self.rnn2 = nn.GRU(embedding_dim,\n",
        "                          hidden_dim,\n",
        "                          num_layers = n_layers,\n",
        "                          bidirectional = bidirectional,\n",
        "                          batch_first = True,\n",
        "                          dropout = 0 if n_layers < 2 else dropout)\n",
        "                \n",
        "        self.out = nn.Linear(hidden_dim * 2 * 2 if bidirectional else hidden_dim * 2, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, comment, code):\n",
        "        \n",
        "        #text = [batch size, sent len]\n",
        "                \n",
        "        with torch.no_grad():\n",
        "            embedded1 = self.bert(comment)[0]\n",
        "            embedded2 = self.bert(code)[0]\n",
        "                \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        _, hidden1 = self.rnn1(embedded1)\n",
        "        _, hidden2 = self.rnn2(embedded2)\n",
        "        \n",
        "        #hidden = [n layers * n directions, batch size, emb dim]\n",
        "        \n",
        "        if self.rnn1.bidirectional:\n",
        "\n",
        "            hidden1 = self.dropout(torch.cat((hidden1[-2,:,:], hidden1[-1,:,:]), dim = 1))\n",
        "            hidden2 = self.dropout(torch.cat((hidden2[-2,:,:], hidden2[-1,:,:]), dim = 1))\n",
        "        else:\n",
        "            hidden1 = self.dropout(hidden1[-1,:,:])\n",
        "            hidden2 = self.dropout(hidden2[-1,:,:])\n",
        "                \n",
        "        #hidden = [batch size, hid dim]\n",
        "        \n",
        "        output = self.out(torch.cat((hidden1, hidden2), dim=1))\n",
        "        \n",
        "        #output = [batch size, out dim]\n",
        "        \n",
        "        return output"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sezri_nhRQtP"
      },
      "source": [
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.25\n",
        "\n",
        "model = BERTGRU(bert,\n",
        "                HIDDEN_DIM,\n",
        "                OUTPUT_DIM,\n",
        "                N_LAYERS,\n",
        "                BIDIRECTIONAL,\n",
        "                DROPOUT)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfSy80FURUyZ",
        "outputId": "7722ce2e-0037-4a29-e296-0287cd49f179"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 5,518,337 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtG1uO-CRWlL"
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if name.startswith('bert'):\n",
        "        param.requires_grad = False"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjCXL99DRZ69",
        "outputId": "8a2bc18d-7a0a-4916-e84d-4515447cff02"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 5,518,337 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbB3aaYKRder",
        "outputId": "dd6455fe-8f1e-457a-e8cb-b708c6519c01"
      },
      "source": [
        "for name, param in model.named_parameters():                \n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rnn1.weight_ih_l0\n",
            "rnn1.weight_hh_l0\n",
            "rnn1.bias_ih_l0\n",
            "rnn1.bias_hh_l0\n",
            "rnn1.weight_ih_l0_reverse\n",
            "rnn1.weight_hh_l0_reverse\n",
            "rnn1.bias_ih_l0_reverse\n",
            "rnn1.bias_hh_l0_reverse\n",
            "rnn1.weight_ih_l1\n",
            "rnn1.weight_hh_l1\n",
            "rnn1.bias_ih_l1\n",
            "rnn1.bias_hh_l1\n",
            "rnn1.weight_ih_l1_reverse\n",
            "rnn1.weight_hh_l1_reverse\n",
            "rnn1.bias_ih_l1_reverse\n",
            "rnn1.bias_hh_l1_reverse\n",
            "rnn2.weight_ih_l0\n",
            "rnn2.weight_hh_l0\n",
            "rnn2.bias_ih_l0\n",
            "rnn2.bias_hh_l0\n",
            "rnn2.weight_ih_l0_reverse\n",
            "rnn2.weight_hh_l0_reverse\n",
            "rnn2.bias_ih_l0_reverse\n",
            "rnn2.bias_hh_l0_reverse\n",
            "rnn2.weight_ih_l1\n",
            "rnn2.weight_hh_l1\n",
            "rnn2.bias_ih_l1\n",
            "rnn2.bias_hh_l1\n",
            "rnn2.weight_ih_l1_reverse\n",
            "rnn2.weight_hh_l1_reverse\n",
            "rnn2.bias_ih_l1_reverse\n",
            "rnn2.bias_hh_l1_reverse\n",
            "out.weight\n",
            "out.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8abt_mKRf3A"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97pm3IptRhpc"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElxIFyW7RjKE"
      },
      "source": [
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znl89Tb1RmAC"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sQ_5WFbRodK"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.c, batch.m).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.y)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjVZTtYYRtgD"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.c, batch.m).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.y)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.y)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX7eqSqqR2Ev"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LahyAHbGR3pl",
        "outputId": "aca83460-922e-4855-dbcc-8957dd73d1ba"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "        \n",
        "    end_time = time.time()\n",
        "        \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "        \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut6-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 17m 50s\n",
            "\tTrain Loss: 0.700 | Train Acc: 50.81%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 52.48%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}