{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TexasPytorch.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N5A6hteFMa3"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDbtfOTlEdZE"
      },
      "source": [
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3DzuoEeFtOq"
      },
      "source": [
        "file_id = '1affGFPxQ1RmV73Vk7tDNaDSbUWP4YDHP'\n",
        "destination = 'texas.json'\n",
        "download_file_from_google_drive(file_id, destination)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7dua3kfFu4W"
      },
      "source": [
        "import json\n",
        "with open('texas.json', 'r') as fp:\n",
        "    texas = json.load(fp)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X_VCQL4FwSq",
        "outputId": "37fae037-f831-42c6-aa6a-93cc9c5e7416"
      },
      "source": [
        "texas[0].keys()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['C1', 'C2', 'M1', 'M2'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqCM4eq_F2gl"
      },
      "source": [
        "# Filter lenght\n",
        "import numpy as np\n",
        "\n",
        "comment_len_bound = 3\n",
        "code_len_bound = 5\n",
        "\n",
        "mask = np.ones(len(texas), dtype=bool)\n",
        "\n",
        "for i, data in enumerate(texas):\n",
        "  C1 = data['C1']\n",
        "  C2 = data['C2']\n",
        "  M1 = data['M1']\n",
        "  M2 = data['M2']\n",
        "  if len(C1) < comment_len_bound or len(C2) < comment_len_bound or len(M1) < code_len_bound or len(M2) < code_len_bound:\n",
        "    mask[i] = False\n",
        "texas = np.array(texas)[mask]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRpBeO27GhGj",
        "outputId": "1f0a60e1-0dfa-4342-b41e-5dc7964d00b6"
      },
      "source": [
        "len(texas)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2926"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cta7cg1zG19Q"
      },
      "source": [
        "# Label Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q1nz9MXG4Sj"
      },
      "source": [
        "def create_dataset(data):\n",
        "  dataset = []\n",
        "  for sample in data:\n",
        "    C1 = sample['C1']\n",
        "    C2 = sample['C2']\n",
        "    M1 = sample['M1']\n",
        "    M2 = sample['M2']\n",
        "    # New code and old comment --> inconsistency \n",
        "    dataset.append({'C': C1, 'M': M2, 'Y': 'INCONS'})\n",
        "    # New code and new comment --> consistency\n",
        "    dataset.append({'C': C2, 'M': M2, 'Y': 'CONS'})\n",
        "  return dataset"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiZT6dlQOIb_",
        "outputId": "1a7e9721-a55e-41be-e4a5-e7ecbb06c726"
      },
      "source": [
        "dataset = create_dataset(texas)\n",
        "dataset[0]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': ['crash',\n",
              "  'report',\n",
              "  'data',\n",
              "  'read',\n",
              "  'from',\n",
              "  'the',\n",
              "  'supplied',\n",
              "  'input',\n",
              "  'stream'],\n",
              " 'M': ['non',\n",
              "  'public',\n",
              "  'crash',\n",
              "  'report',\n",
              "  'data',\n",
              "  'load',\n",
              "  'non',\n",
              "  'file',\n",
              "  'file',\n",
              "  'throws',\n",
              "  'ioexception',\n",
              "  'jsonexception',\n",
              "  'final',\n",
              "  'input',\n",
              "  'stream',\n",
              "  'in',\n",
              "  'new',\n",
              "  'buffered',\n",
              "  'input',\n",
              "  'stream',\n",
              "  'new',\n",
              "  'file',\n",
              "  'input',\n",
              "  'stream',\n",
              "  'file',\n",
              "  'acraconstants',\n",
              "  'default',\n",
              "  'buffer',\n",
              "  'size',\n",
              "  'in',\n",
              "  'bytes',\n",
              "  'try',\n",
              "  'return',\n",
              "  'json',\n",
              "  'utils',\n",
              "  'to',\n",
              "  'crash',\n",
              "  'report',\n",
              "  'data',\n",
              "  'new',\n",
              "  'jsonobject',\n",
              "  'ioutils',\n",
              "  'stream',\n",
              "  'to',\n",
              "  'string',\n",
              "  'in',\n",
              "  'finally',\n",
              "  'ioutils',\n",
              "  'safe',\n",
              "  'close',\n",
              "  'in'],\n",
              " 'Y': 'INCONS'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnHSBHYOPFr4"
      },
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "Path(\"data\").mkdir(parents=True, exist_ok=True)\n",
        "with open('data/dataset.json', 'w') as f:\n",
        "  for data in dataset:\n",
        "    f.write(json.dumps(data) + '\\n')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRA3_EylQfoZ",
        "outputId": "f8d6878d-b097-4547-a70e-c1952d1bcc80"
      },
      "source": [
        "with open('data/dataset.json', 'r') as f:\n",
        "  print(f.read()[:500])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"C\": [\"crash\", \"report\", \"data\", \"read\", \"from\", \"the\", \"supplied\", \"input\", \"stream\"], \"M\": [\"non\", \"public\", \"crash\", \"report\", \"data\", \"load\", \"non\", \"file\", \"file\", \"throws\", \"ioexception\", \"jsonexception\", \"final\", \"input\", \"stream\", \"in\", \"new\", \"buffered\", \"input\", \"stream\", \"new\", \"file\", \"input\", \"stream\", \"file\", \"acraconstants\", \"default\", \"buffer\", \"size\", \"in\", \"bytes\", \"try\", \"return\", \"json\", \"utils\", \"to\", \"crash\", \"report\", \"data\", \"new\", \"jsonobject\", \"ioutils\", \"stream\", \"to\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceB2djW1GlCQ"
      },
      "source": [
        "# NBOW2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzIo8FsXGohQ"
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "CODE = data.Field(tokenize=lambda x: x)\n",
        "COMMENT = data.Field(tokenize=lambda x: x)\n",
        "LABEL = data.LabelField(dtype = torch.float)\n",
        "fields = {'C': ('c', COMMENT), 'M': ('m', CODE), 'Y': ('y', LABEL)}"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXP_So_3O_Hz"
      },
      "source": [
        "my_data = data.TabularDataset(\n",
        "                            path = 'data/dataset.json',\n",
        "                            format = 'json',\n",
        "                            fields = fields\n",
        ")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzB-ghUQSmEv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b9ea5a0-001a-4f1e-88cf-59c72c0b8f98"
      },
      "source": [
        "print(vars(my_data[0]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'c': ['crash', 'report', 'data', 'read', 'from', 'the', 'supplied', 'input', 'stream'], 'm': ['non', 'public', 'crash', 'report', 'data', 'load', 'non', 'file', 'file', 'throws', 'ioexception', 'jsonexception', 'final', 'input', 'stream', 'in', 'new', 'buffered', 'input', 'stream', 'new', 'file', 'input', 'stream', 'file', 'acraconstants', 'default', 'buffer', 'size', 'in', 'bytes', 'try', 'return', 'json', 'utils', 'to', 'crash', 'report', 'data', 'new', 'jsonobject', 'ioutils', 'stream', 'to', 'string', 'in', 'finally', 'ioutils', 'safe', 'close', 'in'], 'y': 'INCONS'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVxmBOqxqcdH"
      },
      "source": [
        "import random\n",
        "SEED = 1234\n",
        "train_data, test_data = my_data.split(random_state = random.seed(SEED))\n",
        "train_data, val_data = train_data.split(split_ratio=0.8, random_state = random.seed(SEED))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CYY7rYsqs8s"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "COMMENT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE)\n",
        "\n",
        "CODE.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkFL5DBPq6gj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "974e3bcd-174a-4d08-9da6-6dbee4b0c99d"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(val_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 3277\n",
            "Number of validation examples: 819\n",
            "Number of testing examples: 1756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa74zmNXrGbA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "060c7185-98ae-4542-c260-4524c90ff262"
      },
      "source": [
        "print(f\"Unique tokens in COMMENT vocabulary: {len(COMMENT.vocab)}\")\n",
        "print(f\"Unique tokens in CODE vocabulary: {len(CODE.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in COMMENT vocabulary: 3009\n",
            "Unique tokens in CODE vocabulary: 4369\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGidh3DirTMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "698d8e08-fe5a-4b49-de26-ca6b57750d06"
      },
      "source": [
        "print(CODE.vocab.freqs.most_common(20))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('get', 6038), ('return', 5407), ('if', 3955), ('string', 3701), ('str', 3201), ('num', 3067), ('new', 3052), ('public', 2743), ('int', 2016), ('final', 1855), ('name', 1633), ('list', 1585), ('value', 1579), ('type', 1543), ('is', 1367), ('to', 1263), ('class', 1232), ('length', 1230), ('result', 1201), ('exception', 1184)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAwSdvsbrXPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1094a12-289a-4ec7-9fd9-4ba4abf144ce"
      },
      "source": [
        "print(COMMENT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 3535), ('of', 1238), ('a', 1169), ('if', 1127), ('is', 744), ('or', 661), ('null', 576), ('to', 473), ('this', 469), ('for', 396), ('an', 365), ('in', 352), ('true', 350), ('that', 319), ('value', 313), ('given', 262), ('list', 258), ('not', 248), ('string', 243), ('with', 232)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otV75gtXrZnw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30076175-bf4d-4dcc-a2a9-cd0fcc89cd36"
      },
      "source": [
        "print(COMMENT.vocab.itos[:10])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', 'of', 'a', 'if', 'is', 'or', 'null', 'to']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAvTRxZMrfAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ce86d01-0b2c-4c85-c0b4-13c16358e503"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f6adb4b8840>, {'INCONS': 0, 'CONS': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJonXfC1tk1s"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, val_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key=lambda x: len(x.c) + len(x.m), # the BucketIterator needs to be told what function it should use to group the data.\n",
        "    sort_within_batch=False,\n",
        "    device = device)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCK1oVnwvIFE"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NBOW2(nn.Module):\n",
        "    def __init__(self, comment_vocab_size, code_vocab_size, embedding_dim, output_dim, comment_pad_idx, code_pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding1 = nn.Embedding(comment_vocab_size, embedding_dim, padding_idx=comment_pad_idx)\n",
        "        self.embedding2 = nn.Embedding(code_vocab_size, embedding_dim, padding_idx=code_pad_idx)\n",
        "        \n",
        "        self.fc = nn.Linear(2 * embedding_dim, output_dim)\n",
        "        \n",
        "        self.a1 = torch.nn.Parameter(torch.zeros(embedding_dim, 1))\n",
        "        self.a2 = torch.nn.Parameter(torch.zeros(embedding_dim, 1))\n",
        "        \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "        \n",
        "    def forward(self, comment, code):\n",
        "        \n",
        "        #comment = [comment len, batch size]\n",
        "        #code = [code len, batch size]\n",
        "        \n",
        "        embedded1 = self.embedding1(comment)\n",
        "        embedded2 = self.embedding2(code)\n",
        "\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        embedded1 = embedded1.permute(1, 0, 2)\n",
        "        embedded2 = embedded2.permute(1, 0, 2)\n",
        "  \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        # Get the scalar word importance weights for each word w\n",
        "        # a: [emb dim, 1]\n",
        "        # aw: [batch size, sent len, 1]\n",
        "        \n",
        "        aw1 = torch.matmul(embedded1, self.a1)\n",
        "        aw1 = self.sigmoid(aw1)\n",
        "\n",
        "        aw2 = torch.matmul(embedded2, self.a2)\n",
        "        aw2 = self.sigmoid(aw2)\n",
        "        \n",
        "        # w_emb: [batch size, sent len, emb dim]\n",
        "        weighted_embed1 = embedded1 * aw1\n",
        "        weighted_embed2 = embedded2 * aw2\n",
        "\n",
        "        pooled1 = F.avg_pool2d(weighted_embed1, (weighted_embed1.shape[1], 1)).squeeze(1) \n",
        "        pooled2 = F.avg_pool2d(weighted_embed2, (weighted_embed2.shape[1], 1)).squeeze(1)\n",
        "        #pooled = [batch size, embedding_dim]\n",
        "\n",
        "        code_comment = torch.cat((pooled1, pooled2), dim=1)\n",
        "                \n",
        "        return self.fc(code_comment)\n",
        "      \n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "\n",
        "        self.a1.data.uniform_(0.0, 1.0)\n",
        "        self.a2.data.uniform_(0.0, 1.0)\n",
        "\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ctv05YYUvIzg"
      },
      "source": [
        "CODE_INPUT_DIM = len(CODE.vocab)\n",
        "COMMENT_INPUT_DIM = len(COMMENT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "OUTPUT_DIM = 1\n",
        "COMMENT_PAD_IDX = COMMENT.vocab.stoi[COMMENT.pad_token]\n",
        "CODE_PAD_IDX = CODE.vocab.stoi[CODE.pad_token]\n",
        "model = NBOW2(COMMENT_INPUT_DIM, CODE_INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, COMMENT_PAD_IDX, CODE_PAD_IDX)\n",
        "model.init_weights()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3DImvooxhTx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e06f64f-4f3e-4d27-925a-324965b6e155"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 738,201 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNpIAZG4xjax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "332e06fd-f863-4d04-ca9f-75feffdab653"
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a1\n",
            "a2\n",
            "embedding1.weight\n",
            "embedding2.weight\n",
            "fc.weight\n",
            "fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9J-fgUYQxspf"
      },
      "source": [
        "COMMENT_UNK_IDX = COMMENT.vocab.stoi[COMMENT.unk_token]\n",
        "CODE_UNK_IDX = CODE.vocab.stoi[CODE.unk_token]\n",
        "\n",
        "model.embedding1.weight.data[COMMENT_UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding1.weight.data[COMMENT_PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "\n",
        "model.embedding2.weight.data[CODE_UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding2.weight.data[CODE_PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjIfSRGUx9NL"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CecIOIwx-m8"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljjH-Cvpx_2J"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLOwDs0ByBAc"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.c, batch.m).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.y)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbL07iklyCgk"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.c, batch.m).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.y)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.y)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeaVkivryNMI"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQkB-UrUyOTM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21e5b502-958a-4139-b982-6862052b7e3c"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.698 | Train Acc: 50.19%\n",
            "\t Val. Loss: 0.725 |  Val. Acc: 48.00%\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.691 | Train Acc: 51.75%\n",
            "\t Val. Loss: 0.727 |  Val. Acc: 46.20%\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.689 | Train Acc: 53.17%\n",
            "\t Val. Loss: 0.731 |  Val. Acc: 45.21%\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.685 | Train Acc: 55.21%\n",
            "\t Val. Loss: 0.736 |  Val. Acc: 46.53%\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.683 | Train Acc: 56.18%\n",
            "\t Val. Loss: 0.742 |  Val. Acc: 44.91%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAR3mCE4kji5"
      },
      "source": [
        "# NBOW2 + Pretrained Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Y2CuHFNkji6"
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "CODE = data.Field(tokenize=lambda x: x, preprocessing=lambda x: [w.replace('▁', '') for w in x])\n",
        "COMMENT = data.Field(tokenize=lambda x: x, preprocessing=lambda x: [w.replace('▁', '') for w in x])\n",
        "LABEL = data.LabelField(dtype = torch.float)\n",
        "fields = {'C': ('c', COMMENT), 'M': ('m', CODE), 'Y': ('y', LABEL)}"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xz7GLktkji7"
      },
      "source": [
        "my_data = data.TabularDataset(\n",
        "                            path = 'data/dataset.json',\n",
        "                            format = 'json',\n",
        "                            fields = fields\n",
        ")"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnSqGCUVkji7",
        "outputId": "1b59ba85-2d2c-4183-aad9-c6a123708aa0"
      },
      "source": [
        "print(vars(my_data[0]))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'c': ['crash', 'report', 'data', 'read', 'from', 'the', 'supplied', 'input', 'stream'], 'm': ['non', 'public', 'crash', 'report', 'data', 'load', 'non', 'file', 'file', 'throws', 'ioexception', 'jsonexception', 'final', 'input', 'stream', 'in', 'new', 'buffered', 'input', 'stream', 'new', 'file', 'input', 'stream', 'file', 'acraconstants', 'default', 'buffer', 'size', 'in', 'bytes', 'try', 'return', 'json', 'utils', 'to', 'crash', 'report', 'data', 'new', 'jsonobject', 'ioutils', 'stream', 'to', 'string', 'in', 'finally', 'ioutils', 'safe', 'close', 'in'], 'y': 'INCONS'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KCK34Q2kji9"
      },
      "source": [
        "import random\n",
        "SEED = 1234\n",
        "train_data, test_data = my_data.split(random_state = random.seed(SEED))\n",
        "train_data, val_data = train_data.split(split_ratio=0.8, random_state = random.seed(SEED))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIOn3_cnkji9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8a49db8-e090-46f2-9b20-9a5f95f9195a"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "COMMENT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE,  \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "CODE.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE,  \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:28, 2.22MB/s]                           \n",
            "100%|█████████▉| 398484/400000 [00:16<00:00, 24368.43it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XS_Y7YIEyhQG",
        "outputId": "e100ac57-4943-460d-fe4d-31a9d06f55fc"
      },
      "source": [
        "import torchtext.vocab\n",
        "\n",
        "glove = torchtext.vocab.GloVe(name = '6B', dim = 100)\n",
        "\n",
        "print(f'There are {len(glove.itos)} words in the vocabulary')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 400000 words in the vocabulary\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Qadd0Xdyj11",
        "outputId": "7c0050fb-3024-4567-ebca-b7bee7a6506e"
      },
      "source": [
        "count_intersect = 0\n",
        "for w in COMMENT.vocab.itos:\n",
        "  if w in glove.stoi:\n",
        "    count_intersect += 1\n",
        "\n",
        "print(count_intersect / len(COMMENT.vocab.itos))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9016284479893653\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDDc_AJ6z40O",
        "outputId": "534b59aa-1e46-4af2-ee88-1681cbc3c8ec"
      },
      "source": [
        "count_intersect = 0\n",
        "for w in CODE.vocab.itos:\n",
        "  if w in glove.stoi:\n",
        "    count_intersect += 1\n",
        "\n",
        "print(count_intersect / len(CODE.vocab.itos))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7896543831540398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw0ldATSkji9",
        "outputId": "b870b635-c125-4de7-c964-829613d78b91"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(val_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 3277\n",
            "Number of validation examples: 819\n",
            "Number of testing examples: 1756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__sXspo9kji9",
        "outputId": "3d62c9ac-334d-4c06-df5a-fc1e8c0b5fe1"
      },
      "source": [
        "print(f\"Unique tokens in COMMENT vocabulary: {len(COMMENT.vocab)}\")\n",
        "print(f\"Unique tokens in CODE vocabulary: {len(CODE.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in COMMENT vocabulary: 3009\n",
            "Unique tokens in CODE vocabulary: 4369\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBs0hpx5kji-",
        "outputId": "3d3ed6e8-9827-4955-d79b-97cb8af0b8a5"
      },
      "source": [
        "print(CODE.vocab.freqs.most_common(20))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('get', 6038), ('return', 5407), ('if', 3955), ('string', 3701), ('str', 3201), ('num', 3067), ('new', 3052), ('public', 2743), ('int', 2016), ('final', 1855), ('name', 1633), ('list', 1585), ('value', 1579), ('type', 1543), ('is', 1367), ('to', 1263), ('class', 1232), ('length', 1230), ('result', 1201), ('exception', 1184)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCzAZ_HWkji-",
        "outputId": "23160b40-c31d-4403-d3eb-d134fdc0b7da"
      },
      "source": [
        "print(COMMENT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 3535), ('of', 1238), ('a', 1169), ('if', 1127), ('is', 744), ('or', 661), ('null', 576), ('to', 473), ('this', 469), ('for', 396), ('an', 365), ('in', 352), ('true', 350), ('that', 319), ('value', 313), ('given', 262), ('list', 258), ('not', 248), ('string', 243), ('with', 232)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ii3sNOyAkji-",
        "outputId": "af76a92c-7a02-4c26-cb90-8f9357252c73"
      },
      "source": [
        "print(COMMENT.vocab.itos[:10])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', 'of', 'a', 'if', 'is', 'or', 'null', 'to']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPmXUxO3kji-",
        "outputId": "e0bb8999-4b94-4c18-f9f5-0c6561382573"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f6adb4b8840>, {'INCONS': 0, 'CONS': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ju2SLHnJkji-"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, val_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key=lambda x: len(x.c) + len(x.m), # the BucketIterator needs to be told what function it should use to group the data.\n",
        "    sort_within_batch=False,\n",
        "    device = device)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHszgTc6kji-"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NBOW2(nn.Module):\n",
        "    def __init__(self, comment_vocab_size, code_vocab_size, embedding_dim, output_dim, \n",
        "                 comment_pad_idx, code_pad_idx, dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding1 = nn.Embedding(comment_vocab_size, embedding_dim, padding_idx=comment_pad_idx)\n",
        "        self.embedding2 = nn.Embedding(code_vocab_size, embedding_dim, padding_idx=code_pad_idx)\n",
        "        \n",
        "        self.fc = nn.Linear(2 * embedding_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.a1 = torch.nn.Parameter(torch.zeros(embedding_dim, 1))\n",
        "        self.a2 = torch.nn.Parameter(torch.zeros(embedding_dim, 1))\n",
        "        \n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "        \n",
        "    def forward(self, comment, code):\n",
        "        \n",
        "        #comment = [comment len, batch size]\n",
        "        #code = [code len, batch size]\n",
        "        \n",
        "        embedded1 = self.embedding1(comment)\n",
        "        embedded2 = self.embedding2(code)\n",
        "\n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        embedded1 = embedded1.permute(1, 0, 2)\n",
        "        embedded2 = embedded2.permute(1, 0, 2)\n",
        "  \n",
        "        #embedded = [batch size, sent len, emb dim]\n",
        "        \n",
        "        # Get the scalar word importance weights for each word w\n",
        "        # a: [emb dim, 1]\n",
        "        # aw: [batch size, sent len, 1]\n",
        "        \n",
        "        aw1 = torch.matmul(embedded1, self.a1)\n",
        "        aw1 = self.sigmoid(aw1)\n",
        "\n",
        "        aw2 = torch.matmul(embedded2, self.a2)\n",
        "        aw2 = self.sigmoid(aw2)\n",
        "        \n",
        "        # w_emb: [batch size, sent len, emb dim]\n",
        "        weighted_embed1 = embedded1 * aw1\n",
        "        weighted_embed2 = embedded2 * aw2\n",
        "\n",
        "        pooled1 = F.avg_pool2d(weighted_embed1, (weighted_embed1.shape[1], 1)).squeeze(1) \n",
        "        pooled2 = F.avg_pool2d(weighted_embed2, (weighted_embed2.shape[1], 1)).squeeze(1)\n",
        "        #pooled = [batch size, embedding_dim]\n",
        "\n",
        "        code_comment = self.dropout(torch.cat((pooled1, pooled2), dim=1))\n",
        "                \n",
        "        return self.fc(code_comment)\n",
        "      \n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "\n",
        "        self.a1.data.uniform_(0.0, 1.0)\n",
        "        self.a2.data.uniform_(0.0, 1.0)\n",
        "\n",
        "        self.fc.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc.bias.data.zero_()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQH1ETBXkji-"
      },
      "source": [
        "CODE_INPUT_DIM = len(CODE.vocab)\n",
        "COMMENT_INPUT_DIM = len(COMMENT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "OUTPUT_DIM = 1\n",
        "COMMENT_PAD_IDX = COMMENT.vocab.stoi[COMMENT.pad_token]\n",
        "CODE_PAD_IDX = CODE.vocab.stoi[CODE.pad_token]\n",
        "DROPOUT = 0.5\n",
        "\n",
        "model = NBOW2(COMMENT_INPUT_DIM, CODE_INPUT_DIM, EMBEDDING_DIM, OUTPUT_DIM, COMMENT_PAD_IDX, CODE_PAD_IDX, DROPOUT)\n",
        "model.init_weights()"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmysTxOtqbo8"
      },
      "source": [
        ""
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JIkh4JGkji_",
        "outputId": "26c877ef-4b6a-42a4-ef6b-c3595118826f"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 738,201 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmmb4_qikji_",
        "outputId": "0c146f78-8723-4016-f33f-ded6047d76d6"
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a1\n",
            "a2\n",
            "embedding1.weight\n",
            "embedding2.weight\n",
            "fc.weight\n",
            "fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAPh1bonqekn",
        "outputId": "55797fbb-1099-41f2-bf3f-1fb7ea880889"
      },
      "source": [
        "pretrained_embeddings = COMMENT.vocab.vectors\n",
        "\n",
        "model.embedding1.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "pretrained_embeddings = CODE.vocab.vectors\n",
        "\n",
        "model.embedding2.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0199,  0.2426, -0.7804,  ..., -0.6855, -0.7572,  1.1121],\n",
              "        [-0.8491, -0.9379, -1.0158,  ..., -1.1613,  0.1143,  0.6031],\n",
              "        [ 0.1443,  0.4395,  0.5832,  ...,  0.5013,  0.4954,  0.4992],\n",
              "        ...,\n",
              "        [ 0.4221,  0.6307, -0.1291,  ...,  0.1045,  0.1854, -0.4767],\n",
              "        [-0.0274, -0.3202,  0.4358,  ...,  0.3812,  0.2655,  0.5815],\n",
              "        [-0.1788, -0.4827, -0.8316,  ..., -1.4720, -1.3727,  1.4800]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjsNrBChkji_"
      },
      "source": [
        "COMMENT_UNK_IDX = COMMENT.vocab.stoi[COMMENT.unk_token]\n",
        "CODE_UNK_IDX = CODE.vocab.stoi[CODE.unk_token]\n",
        "\n",
        "model.embedding1.weight.data[COMMENT_UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding1.weight.data[COMMENT_PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "\n",
        "model.embedding2.weight.data[CODE_UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding2.weight.data[CODE_PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drjQlJL_qd3l"
      },
      "source": [
        ""
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZUSW8Rqkji_"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66zLWzydkji_"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4CGCCV0kji_"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PG3x059kji_"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        predictions = model(batch.c, batch.m).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, batch.y)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZdt_5sakji_"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            predictions = model(batch.c, batch.m).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.y)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.y)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DMGY6pZkji_"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKLd7VBBkji_",
        "outputId": "f365d290-7265-4711-bd04-c209743360fa"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.694 | Train Acc: 49.93%\n",
            "\t Val. Loss: 0.700 |  Val. Acc: 47.79%\n",
            "Epoch: 02 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.690 | Train Acc: 53.29%\n",
            "\t Val. Loss: 0.703 |  Val. Acc: 48.03%\n",
            "Epoch: 03 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.691 | Train Acc: 52.84%\n",
            "\t Val. Loss: 0.706 |  Val. Acc: 48.36%\n",
            "Epoch: 04 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.688 | Train Acc: 54.40%\n",
            "\t Val. Loss: 0.709 |  Val. Acc: 47.10%\n",
            "Epoch: 05 | Epoch Time: 0m 0s\n",
            "\tTrain Loss: 0.688 | Train Acc: 55.27%\n",
            "\t Val. Loss: 0.712 |  Val. Acc: 46.20%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "av6t1uro3G2b",
        "outputId": "2b4d1f03-12a9-4dca-b770-67834c07fe27"
      },
      "source": [
        "model.load_state_dict(torch.load('tut3-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.702 | Test Acc: 49.31%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRqfoqHV5AJY"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA52OZY45AJY"
      },
      "source": [
        "import torch\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "CODE = data.Field(tokenize=lambda x: x, preprocessing=lambda x: [w.replace('▁', '') for w in x], include_lengths = True)\n",
        "COMMENT = data.Field(tokenize=lambda x: x, preprocessing=lambda x: [w.replace('▁', '') for w in x], include_lengths = True)\n",
        "LABEL = data.LabelField(dtype = torch.float)\n",
        "fields = {'C': ('c', COMMENT), 'M': ('m', CODE), 'Y': ('y', LABEL)}"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUFpbl6C5AJZ"
      },
      "source": [
        "my_data = data.TabularDataset(\n",
        "                            path = 'data/dataset.json',\n",
        "                            format = 'json',\n",
        "                            fields = fields\n",
        ")"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfVf4KR_5AJZ",
        "outputId": "b876f27c-a904-4ca5-9e69-68339a3e8ff1"
      },
      "source": [
        "print(vars(my_data[0]))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'c': ['crash', 'report', 'data', 'read', 'from', 'the', 'supplied', 'input', 'stream'], 'm': ['non', 'public', 'crash', 'report', 'data', 'load', 'non', 'file', 'file', 'throws', 'ioexception', 'jsonexception', 'final', 'input', 'stream', 'in', 'new', 'buffered', 'input', 'stream', 'new', 'file', 'input', 'stream', 'file', 'acraconstants', 'default', 'buffer', 'size', 'in', 'bytes', 'try', 'return', 'json', 'utils', 'to', 'crash', 'report', 'data', 'new', 'jsonobject', 'ioutils', 'stream', 'to', 'string', 'in', 'finally', 'ioutils', 'safe', 'close', 'in'], 'y': 'INCONS'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdDOmTPF5AJb"
      },
      "source": [
        "import random\n",
        "SEED = 1234\n",
        "train_data, test_data = my_data.split(random_state = random.seed(SEED))\n",
        "train_data, val_data = train_data.split(split_ratio=0.8, random_state = random.seed(SEED))"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrX0nSsv5AJb"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "\n",
        "COMMENT.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE,  \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "CODE.build_vocab(train_data, \n",
        "                 max_size = MAX_VOCAB_SIZE,  \n",
        "                 vectors = \"glove.6B.100d\", \n",
        "                 unk_init = torch.Tensor.normal_)\n",
        "\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoLv3euS5AJb",
        "outputId": "f524129a-80d5-4f03-d163-90835101e139"
      },
      "source": [
        "import torchtext.vocab\n",
        "\n",
        "glove = torchtext.vocab.GloVe(name = '6B', dim = 100)\n",
        "\n",
        "print(f'There are {len(glove.itos)} words in the vocabulary')"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 400000 words in the vocabulary\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHZUpnYK5AJc",
        "outputId": "9edbd664-3b63-4b14-d5af-84602aaa0a74"
      },
      "source": [
        "count_intersect = 0\n",
        "for w in COMMENT.vocab.itos:\n",
        "  if w in glove.stoi:\n",
        "    count_intersect += 1\n",
        "\n",
        "print(count_intersect / len(COMMENT.vocab.itos))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9016284479893653\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3K_AQ7U5AJc",
        "outputId": "ea40c60a-d021-4276-ff1d-cbbf1f2f93c6"
      },
      "source": [
        "count_intersect = 0\n",
        "for w in CODE.vocab.itos:\n",
        "  if w in glove.stoi:\n",
        "    count_intersect += 1\n",
        "\n",
        "print(count_intersect / len(CODE.vocab.itos))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7896543831540398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJtW2j015AJc",
        "outputId": "98fc1c75-b51e-4b4f-abeb-8af47a5f7605"
      },
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(val_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 3277\n",
            "Number of validation examples: 819\n",
            "Number of testing examples: 1756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9xeyvhx5AJd",
        "outputId": "7d66a705-60cb-40a7-8dd5-b3467e46518f"
      },
      "source": [
        "print(f\"Unique tokens in COMMENT vocabulary: {len(COMMENT.vocab)}\")\n",
        "print(f\"Unique tokens in CODE vocabulary: {len(CODE.vocab)}\")\n",
        "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique tokens in COMMENT vocabulary: 3009\n",
            "Unique tokens in CODE vocabulary: 4369\n",
            "Unique tokens in LABEL vocabulary: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfIIf2Go5AJd",
        "outputId": "d9f1da45-a039-4eb7-a78a-eadf657759e2"
      },
      "source": [
        "print(CODE.vocab.freqs.most_common(20))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('get', 6038), ('return', 5407), ('if', 3955), ('string', 3701), ('str', 3201), ('num', 3067), ('new', 3052), ('public', 2743), ('int', 2016), ('final', 1855), ('name', 1633), ('list', 1585), ('value', 1579), ('type', 1543), ('is', 1367), ('to', 1263), ('class', 1232), ('length', 1230), ('result', 1201), ('exception', 1184)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hedObpWx5AJd",
        "outputId": "ebd10767-097b-4683-8e70-7828fb52f7b6"
      },
      "source": [
        "print(COMMENT.vocab.freqs.most_common(20))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('the', 3535), ('of', 1238), ('a', 1169), ('if', 1127), ('is', 744), ('or', 661), ('null', 576), ('to', 473), ('this', 469), ('for', 396), ('an', 365), ('in', 352), ('true', 350), ('that', 319), ('value', 313), ('given', 262), ('list', 258), ('not', 248), ('string', 243), ('with', 232)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k-b3EgKo5AJd",
        "outputId": "912bb40f-3e40-48dc-e4ed-4eb8ce1a878c"
      },
      "source": [
        "print(COMMENT.vocab.itos[:10])"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', 'the', 'of', 'a', 'if', 'is', 'or', 'null', 'to']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRSZTBFL5AJe",
        "outputId": "b3fd660e-5d53-4658-da81-4cf311f3ea25"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<function _default_unk_index at 0x7f6adb4b8840>, {'INCONS': 0, 'CONS': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX12gMt65AJe"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, val_data, test_data), \n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort=False,\n",
        "    device = device)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uncc3q3z5AJe"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, comment_vocab_size, code_vocab_size, \n",
        "                 embedding_dim, hidden_dim, output_dim, n_layers, \n",
        "                 bidirectional, comment_pad_idx, code_pad_idx, dropout):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding1 = nn.Embedding(comment_vocab_size, embedding_dim, padding_idx = comment_pad_idx)\n",
        "        self.embedding2 = nn.Embedding(code_vocab_size, embedding_dim, padding_idx = code_pad_idx)\n",
        "        \n",
        "        self.rnn1 = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout)\n",
        "        \n",
        "        self.rnn2 = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           num_layers=n_layers, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout)\n",
        "        \n",
        "\n",
        "\n",
        "        self.fc = nn.Linear(hidden_dim * 2 * 2, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, comment, comment_lengths, code, code_lengths):\n",
        "        \n",
        "        #text = [sent len, batch size]\n",
        "        \n",
        "        embedded1 = self.dropout(self.embedding1(comment))\n",
        "        embedded2 = self.dropout(self.embedding2(code))\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        #pack sequence\n",
        "        packed_embedded1 = nn.utils.rnn.pack_padded_sequence(embedded1, comment_lengths.cpu(), enforce_sorted=False)\n",
        "        packed_output1, (hidden1, cell1) = self.rnn1(packed_embedded1)\n",
        "\n",
        "        packed_embedded2 = nn.utils.rnn.pack_padded_sequence(embedded2, code_lengths.cpu(), enforce_sorted=False)\n",
        "        packed_output2, (hidden2, cell2) = self.rnn2(packed_embedded2)\n",
        "\n",
        "        \n",
        "        #unpack sequence\n",
        "        output1, output_lengths1 = nn.utils.rnn.pad_packed_sequence(packed_output1)\n",
        "        output2, output_lengths2 = nn.utils.rnn.pad_packed_sequence(packed_output1)\n",
        "\n",
        "        #output = [sent len, batch size, hid dim * num directions]\n",
        "        #output over padding tokens are zero tensors\n",
        "        \n",
        "        #hidden = [num layers * num directions, batch size, hid dim]\n",
        "        #cell = [num layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        #and apply dropout\n",
        "        \n",
        "        hidden1 = self.dropout(torch.cat((hidden1[-2,:,:], hidden1[-1,:,:]), dim = 1))\n",
        "        hidden2 = self.dropout(torch.cat((hidden2[-2,:,:], hidden2[-1,:,:]), dim = 1))\n",
        "\n",
        "        hidden = self.dropout(torch.cat((hidden1, hidden2), dim=1))\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "            \n",
        "        return self.fc(hidden)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgrgpb025AJe"
      },
      "source": [
        "CODE_INPUT_DIM = len(CODE.vocab)\n",
        "COMMENT_INPUT_DIM = len(COMMENT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "OUTPUT_DIM = 1\n",
        "COMMENT_PAD_IDX = COMMENT.vocab.stoi[COMMENT.pad_token]\n",
        "CODE_PAD_IDX = CODE.vocab.stoi[CODE.pad_token]\n",
        "DROPOUT = 0.5\n",
        "BIDIRECTIONAL = True\n",
        "N_LAYERS = 2\n",
        "HIDDEN_DIM = 256\n",
        "\n",
        "model = RNN(COMMENT_INPUT_DIM, CODE_INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, COMMENT_PAD_IDX, CODE_PAD_IDX, \n",
        "            DROPOUT)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mz8Btup5AJe"
      },
      "source": [
        ""
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Euv4-dKK5AJe",
        "outputId": "e325866c-c593-49d7-cc30-8d5a55d674ea"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 5,359,113 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwvOB0Pa5AJe",
        "outputId": "38e2e1ed-0aee-4021-caaf-97352748609e"
      },
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embedding1.weight\n",
            "embedding2.weight\n",
            "rnn1.weight_ih_l0\n",
            "rnn1.weight_hh_l0\n",
            "rnn1.bias_ih_l0\n",
            "rnn1.bias_hh_l0\n",
            "rnn1.weight_ih_l0_reverse\n",
            "rnn1.weight_hh_l0_reverse\n",
            "rnn1.bias_ih_l0_reverse\n",
            "rnn1.bias_hh_l0_reverse\n",
            "rnn1.weight_ih_l1\n",
            "rnn1.weight_hh_l1\n",
            "rnn1.bias_ih_l1\n",
            "rnn1.bias_hh_l1\n",
            "rnn1.weight_ih_l1_reverse\n",
            "rnn1.weight_hh_l1_reverse\n",
            "rnn1.bias_ih_l1_reverse\n",
            "rnn1.bias_hh_l1_reverse\n",
            "rnn2.weight_ih_l0\n",
            "rnn2.weight_hh_l0\n",
            "rnn2.bias_ih_l0\n",
            "rnn2.bias_hh_l0\n",
            "rnn2.weight_ih_l0_reverse\n",
            "rnn2.weight_hh_l0_reverse\n",
            "rnn2.bias_ih_l0_reverse\n",
            "rnn2.bias_hh_l0_reverse\n",
            "rnn2.weight_ih_l1\n",
            "rnn2.weight_hh_l1\n",
            "rnn2.bias_ih_l1\n",
            "rnn2.bias_hh_l1\n",
            "rnn2.weight_ih_l1_reverse\n",
            "rnn2.weight_hh_l1_reverse\n",
            "rnn2.bias_ih_l1_reverse\n",
            "rnn2.bias_hh_l1_reverse\n",
            "fc.weight\n",
            "fc.bias\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEtlDJXA5AJe",
        "outputId": "b4cf2206-829e-4d41-f052-66456bab81cb"
      },
      "source": [
        "pretrained_embeddings = COMMENT.vocab.vectors\n",
        "\n",
        "model.embedding1.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "pretrained_embeddings = CODE.vocab.vectors\n",
        "\n",
        "model.embedding2.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.3300,  0.1821, -1.5894,  ..., -0.0754,  1.2962,  1.0890],\n",
              "        [ 1.1888,  0.4801,  2.0308,  ...,  1.4999, -1.8085,  0.8142],\n",
              "        [ 0.1443,  0.4395,  0.5832,  ...,  0.5013,  0.4954,  0.4992],\n",
              "        ...,\n",
              "        [ 0.4221,  0.6307, -0.1291,  ...,  0.1045,  0.1854, -0.4767],\n",
              "        [-0.0274, -0.3202,  0.4358,  ...,  0.3812,  0.2655,  0.5815],\n",
              "        [ 0.6292,  1.3534,  0.4736,  ..., -0.1559,  1.4951, -0.5672]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsJOc_E55AJf"
      },
      "source": [
        "COMMENT_UNK_IDX = COMMENT.vocab.stoi[COMMENT.unk_token]\n",
        "CODE_UNK_IDX = CODE.vocab.stoi[CODE.unk_token]\n",
        "\n",
        "model.embedding1.weight.data[COMMENT_UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding1.weight.data[COMMENT_PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "\n",
        "model.embedding2.weight.data[CODE_UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "model.embedding2.weight.data[CODE_PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYmpHMIz5AJf"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJINOqZL5AJf"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3rpMoGz5AJf"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVdJiKwf5AJf"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for batch in iterator:\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        comment, comment_lens = batch.c\n",
        "        code, code_lens = batch.m\n",
        "        predictions = model(comment, comment_lens, code, code_lens).squeeze(1)\n",
        "            \n",
        "        loss = criterion(predictions, batch.y)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.y)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjuiQ_iY5AJf"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "\n",
        "            comment, comment_lens = batch.c\n",
        "            code, code_lens = batch.m\n",
        "            predictions = model(comment, comment_lens, code, code_lens).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.y)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.y)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TXHnlRw5AJf"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzvfwDid5AJf",
        "outputId": "12de93f8-7366-4792-d6e3-11732eeff3cb"
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'tut3-model.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 7s\n",
            "\tTrain Loss: 0.697 | Train Acc: 51.24%\n",
            "\t Val. Loss: 0.693 |  Val. Acc: 50.26%\n",
            "Epoch: 02 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.693 | Train Acc: 52.47%\n",
            "\t Val. Loss: 0.694 |  Val. Acc: 50.74%\n",
            "Epoch: 03 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.690 | Train Acc: 52.95%\n",
            "\t Val. Loss: 0.698 |  Val. Acc: 50.65%\n",
            "Epoch: 04 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.678 | Train Acc: 56.18%\n",
            "\t Val. Loss: 0.697 |  Val. Acc: 49.80%\n",
            "Epoch: 05 | Epoch Time: 0m 6s\n",
            "\tTrain Loss: 0.666 | Train Acc: 59.90%\n",
            "\t Val. Loss: 0.711 |  Val. Acc: 51.58%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWTJXYYF5AJg",
        "outputId": "46a0777f-1a9e-4db7-ff2e-b4e8daa7468f"
      },
      "source": [
        "model.load_state_dict(torch.load('tut3-model.pt'))\n",
        "\n",
        "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss: 0.693 | Test Acc: 50.73%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}